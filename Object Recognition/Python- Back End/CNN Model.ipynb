{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN Model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2XRG2_N6nO32","colab_type":"code","colab":{}},"source":["pip install python_jwt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d3IImL2NJwj1","colab_type":"code","colab":{}},"source":["pip install gcloud\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"INbgGTdNJw-D","colab_type":"code","colab":{}},"source":["pip install sseclient\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NLwUK93nJxLY","colab_type":"code","colab":{}},"source":["pip install pycrypto\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SrjhxDjWJxga","colab_type":"code","colab":{}},"source":["pip install requests-toolbelt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kd1IpJSXKPYs","colab_type":"code","colab":{}},"source":["pip install firebase"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7rY2TtkfJt6H","colab_type":"code","colab":{}},"source":["from keras.datasets import cifar10\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation, GlobalAveragePooling2D\n","from keras.utils.np_utils import to_categorical as tcg\n","from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n","from keras.optimizers import SGD\n","import numpy as np\n","import cv2\n","from firebase import firebase as fb\n","from google.cloud import storage as st\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zvBv7-hVnxnl","colab_type":"code","outputId":"ff3837cd-7cf1-4e9b-da7e-5ac01949b99d","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["(xtr,ytr),(xte,yte) = cifar10.load_data()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 4s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ooilh8cwodI5","colab_type":"code","colab":{}},"source":["xtr = xtr.astype('float32')/32\n","xte = xte.astype('float32')/32"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JSU5hXVwpGKp","colab_type":"code","colab":{}},"source":["ytr = tcg(ytr)\n","yte = tcg(yte)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cARb2W8OpH6t","colab_type":"code","outputId":"ad0cced9-459c-4385-c21d-ab1e7c57edbd","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = Sequential()\n","\n","model.add(Conv2D(filters=32, kernel_size=(7,7), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=32, kernel_size=(7,7), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(AveragePooling2D(pool_size=(2,2)))\n","model.add(Dropout(.5))\n","\n","model.add(Conv2D(filters=64, kernel_size=(5,5), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=64, kernel_size=(5,5), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(AveragePooling2D(pool_size=(2,2)))\n","model.add(Dropout(.5))\n","\n","model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(AveragePooling2D(pool_size=(2,2)))\n","model.add(Dropout(.5))\n","\n","model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(AveragePooling2D(pool_size=(2,2)))\n","model.add(Dropout(.5))\n","\n","model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(AveragePooling2D(pool_size=(2,2)))\n","model.add(Dropout(.5))\n","\n","model.add(Conv2D(filters=1024, kernel_size=(3,3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=10, kernel_size=(3,3), padding='same'))\n","model.add(GlobalAveragePooling2D())\n","model.add(Activation('softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit(xtr,ytr, validation_data=(xte,yte), epochs=200, batch_size=4096)\n","score = model.evaluate(xte,yte)\n","print(\"Test score:\",score[0])\n","print(\"Text Accuracy:\",score[1]*100)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/200\n","50000/50000 [==============================] - 27s 534us/step - loss: 2.2515 - acc: 0.2010 - val_loss: 9.5692 - val_acc: 0.1645\n","Epoch 2/200\n","50000/50000 [==============================] - 8s 153us/step - loss: 1.8054 - acc: 0.3180 - val_loss: 9.5773 - val_acc: 0.1811\n","Epoch 3/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 1.6727 - acc: 0.3690 - val_loss: 3.1545 - val_acc: 0.2519\n","Epoch 4/200\n","50000/50000 [==============================] - 8s 153us/step - loss: 1.5845 - acc: 0.4075 - val_loss: 2.3738 - val_acc: 0.2895\n","Epoch 5/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 1.5249 - acc: 0.4316 - val_loss: 1.7736 - val_acc: 0.3991\n","Epoch 6/200\n","50000/50000 [==============================] - 8s 153us/step - loss: 1.4681 - acc: 0.4517 - val_loss: 1.7514 - val_acc: 0.4123\n","Epoch 7/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 1.4134 - acc: 0.4776 - val_loss: 1.9096 - val_acc: 0.3891\n","Epoch 8/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 1.3412 - acc: 0.5067 - val_loss: 1.5480 - val_acc: 0.4545\n","Epoch 9/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 1.2949 - acc: 0.5263 - val_loss: 1.5115 - val_acc: 0.4434\n","Epoch 10/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 1.2483 - acc: 0.5452 - val_loss: 1.5639 - val_acc: 0.4303\n","Epoch 11/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 1.1981 - acc: 0.5658 - val_loss: 1.6797 - val_acc: 0.4361\n","Epoch 12/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 1.1685 - acc: 0.5757 - val_loss: 1.6345 - val_acc: 0.4606\n","Epoch 13/200\n","50000/50000 [==============================] - 8s 153us/step - loss: 1.1266 - acc: 0.5919 - val_loss: 1.3020 - val_acc: 0.5238\n","Epoch 14/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 1.0884 - acc: 0.6062 - val_loss: 1.1252 - val_acc: 0.5988\n","Epoch 15/200\n","50000/50000 [==============================] - 8s 153us/step - loss: 1.0644 - acc: 0.6142 - val_loss: 1.2051 - val_acc: 0.5808\n","Epoch 16/200\n","50000/50000 [==============================] - 8s 153us/step - loss: 1.0355 - acc: 0.6249 - val_loss: 1.1281 - val_acc: 0.6092\n","Epoch 17/200\n","50000/50000 [==============================] - 8s 153us/step - loss: 1.0161 - acc: 0.6338 - val_loss: 1.0487 - val_acc: 0.6328\n","Epoch 18/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.9788 - acc: 0.6486 - val_loss: 0.9835 - val_acc: 0.6659\n","Epoch 19/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.9609 - acc: 0.6536 - val_loss: 0.9536 - val_acc: 0.6795\n","Epoch 20/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.9441 - acc: 0.6621 - val_loss: 0.9666 - val_acc: 0.6684\n","Epoch 21/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.9268 - acc: 0.6700 - val_loss: 0.8732 - val_acc: 0.6979\n","Epoch 22/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.9018 - acc: 0.6795 - val_loss: 0.9119 - val_acc: 0.6949\n","Epoch 23/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.8910 - acc: 0.6820 - val_loss: 0.8267 - val_acc: 0.7139\n","Epoch 24/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.8780 - acc: 0.6890 - val_loss: 0.8693 - val_acc: 0.7063\n","Epoch 25/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.8608 - acc: 0.6953 - val_loss: 0.8124 - val_acc: 0.7222\n","Epoch 26/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.8511 - acc: 0.6983 - val_loss: 0.9626 - val_acc: 0.6930\n","Epoch 27/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.8434 - acc: 0.7018 - val_loss: 0.7761 - val_acc: 0.7337\n","Epoch 28/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.8277 - acc: 0.7068 - val_loss: 0.9989 - val_acc: 0.6962\n","Epoch 29/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.8220 - acc: 0.7097 - val_loss: 0.8037 - val_acc: 0.7376\n","Epoch 30/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.8057 - acc: 0.7149 - val_loss: 0.8046 - val_acc: 0.7314\n","Epoch 31/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.8012 - acc: 0.7166 - val_loss: 0.8583 - val_acc: 0.7241\n","Epoch 32/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.7913 - acc: 0.7200 - val_loss: 0.7766 - val_acc: 0.7422\n","Epoch 33/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.7881 - acc: 0.7223 - val_loss: 0.8049 - val_acc: 0.7379\n","Epoch 34/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.7809 - acc: 0.7243 - val_loss: 0.8532 - val_acc: 0.7299\n","Epoch 35/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.7671 - acc: 0.7296 - val_loss: 0.8285 - val_acc: 0.7364\n","Epoch 36/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.7565 - acc: 0.7321 - val_loss: 0.6862 - val_acc: 0.7713\n","Epoch 37/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.7476 - acc: 0.7358 - val_loss: 0.7562 - val_acc: 0.7469\n","Epoch 38/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.7506 - acc: 0.7334 - val_loss: 0.7114 - val_acc: 0.7620\n","Epoch 39/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.7377 - acc: 0.7379 - val_loss: 0.7506 - val_acc: 0.7605\n","Epoch 40/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.7424 - acc: 0.7397 - val_loss: 0.7493 - val_acc: 0.7562\n","Epoch 41/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.7327 - acc: 0.7398 - val_loss: 0.7078 - val_acc: 0.7706\n","Epoch 42/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.7200 - acc: 0.7463 - val_loss: 0.7121 - val_acc: 0.7678\n","Epoch 43/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.7146 - acc: 0.7481 - val_loss: 0.7179 - val_acc: 0.7648\n","Epoch 44/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.7080 - acc: 0.7511 - val_loss: 0.6944 - val_acc: 0.7731\n","Epoch 45/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.7074 - acc: 0.7480 - val_loss: 0.7459 - val_acc: 0.7497\n","Epoch 46/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.7036 - acc: 0.7496 - val_loss: 0.7093 - val_acc: 0.7645\n","Epoch 47/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6936 - acc: 0.7549 - val_loss: 0.7537 - val_acc: 0.7573\n","Epoch 48/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6904 - acc: 0.7597 - val_loss: 0.6309 - val_acc: 0.7902\n","Epoch 49/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6816 - acc: 0.7598 - val_loss: 0.7185 - val_acc: 0.7691\n","Epoch 50/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6823 - acc: 0.7592 - val_loss: 0.6026 - val_acc: 0.7983\n","Epoch 51/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6765 - acc: 0.7618 - val_loss: 0.7161 - val_acc: 0.7679\n","Epoch 52/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6699 - acc: 0.7648 - val_loss: 0.7728 - val_acc: 0.7555\n","Epoch 53/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6725 - acc: 0.7621 - val_loss: 0.6056 - val_acc: 0.7913\n","Epoch 54/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6670 - acc: 0.7649 - val_loss: 0.6443 - val_acc: 0.7870\n","Epoch 55/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6560 - acc: 0.7702 - val_loss: 0.6792 - val_acc: 0.7784\n","Epoch 56/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6519 - acc: 0.7698 - val_loss: 0.5928 - val_acc: 0.8020\n","Epoch 57/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6499 - acc: 0.7701 - val_loss: 0.6231 - val_acc: 0.7927\n","Epoch 58/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6492 - acc: 0.7737 - val_loss: 0.6997 - val_acc: 0.7755\n","Epoch 59/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6450 - acc: 0.7736 - val_loss: 0.6789 - val_acc: 0.7750\n","Epoch 60/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6397 - acc: 0.7769 - val_loss: 0.5927 - val_acc: 0.8018\n","Epoch 61/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6387 - acc: 0.7746 - val_loss: 0.6763 - val_acc: 0.7779\n","Epoch 62/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6317 - acc: 0.7789 - val_loss: 0.6217 - val_acc: 0.7914\n","Epoch 63/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6301 - acc: 0.7775 - val_loss: 0.6624 - val_acc: 0.7794\n","Epoch 64/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6283 - acc: 0.7792 - val_loss: 0.5913 - val_acc: 0.7976\n","Epoch 65/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6276 - acc: 0.7799 - val_loss: 0.6007 - val_acc: 0.7916\n","Epoch 66/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6200 - acc: 0.7831 - val_loss: 0.5908 - val_acc: 0.8001\n","Epoch 67/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6186 - acc: 0.7828 - val_loss: 0.6455 - val_acc: 0.7841\n","Epoch 68/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6086 - acc: 0.7889 - val_loss: 0.6189 - val_acc: 0.7892\n","Epoch 69/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6071 - acc: 0.7883 - val_loss: 0.5978 - val_acc: 0.7988\n","Epoch 70/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6075 - acc: 0.7848 - val_loss: 0.5843 - val_acc: 0.7984\n","Epoch 71/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6024 - acc: 0.7884 - val_loss: 0.5723 - val_acc: 0.8056\n","Epoch 72/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6028 - acc: 0.7897 - val_loss: 0.6695 - val_acc: 0.7872\n","Epoch 73/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.6053 - acc: 0.7886 - val_loss: 0.5697 - val_acc: 0.8042\n","Epoch 74/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5935 - acc: 0.7924 - val_loss: 0.5751 - val_acc: 0.8023\n","Epoch 75/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5826 - acc: 0.7982 - val_loss: 0.5725 - val_acc: 0.8045\n","Epoch 76/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.5837 - acc: 0.7945 - val_loss: 0.6477 - val_acc: 0.7878\n","Epoch 77/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5844 - acc: 0.7948 - val_loss: 0.5350 - val_acc: 0.8130\n","Epoch 78/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5875 - acc: 0.7951 - val_loss: 0.6101 - val_acc: 0.7914\n","Epoch 79/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.5847 - acc: 0.7938 - val_loss: 0.5903 - val_acc: 0.7965\n","Epoch 80/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5828 - acc: 0.7962 - val_loss: 0.5300 - val_acc: 0.8190\n","Epoch 81/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5757 - acc: 0.7986 - val_loss: 0.5665 - val_acc: 0.8095\n","Epoch 82/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5797 - acc: 0.7956 - val_loss: 0.5386 - val_acc: 0.8109\n","Epoch 83/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5790 - acc: 0.7955 - val_loss: 0.5448 - val_acc: 0.8138\n","Epoch 84/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5654 - acc: 0.7999 - val_loss: 0.5801 - val_acc: 0.8064\n","Epoch 85/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5659 - acc: 0.8009 - val_loss: 0.5457 - val_acc: 0.8178\n","Epoch 86/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.5653 - acc: 0.8029 - val_loss: 0.5169 - val_acc: 0.8180\n","Epoch 87/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.5672 - acc: 0.8008 - val_loss: 0.5166 - val_acc: 0.8221\n","Epoch 88/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5573 - acc: 0.8055 - val_loss: 0.5560 - val_acc: 0.8098\n","Epoch 89/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5597 - acc: 0.8036 - val_loss: 0.5372 - val_acc: 0.8169\n","Epoch 90/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.5554 - acc: 0.8070 - val_loss: 0.6173 - val_acc: 0.7875\n","Epoch 91/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5565 - acc: 0.8051 - val_loss: 0.5239 - val_acc: 0.8198\n","Epoch 92/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5596 - acc: 0.8019 - val_loss: 0.5375 - val_acc: 0.8172\n","Epoch 93/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5483 - acc: 0.8076 - val_loss: 0.5092 - val_acc: 0.8266\n","Epoch 94/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5475 - acc: 0.8061 - val_loss: 0.5217 - val_acc: 0.8223\n","Epoch 95/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.5507 - acc: 0.8076 - val_loss: 0.5042 - val_acc: 0.8272\n","Epoch 96/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5478 - acc: 0.8064 - val_loss: 0.5488 - val_acc: 0.8123\n","Epoch 97/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5462 - acc: 0.8094 - val_loss: 0.5690 - val_acc: 0.8074\n","Epoch 98/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5496 - acc: 0.8041 - val_loss: 0.5750 - val_acc: 0.8076\n","Epoch 99/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5389 - acc: 0.8097 - val_loss: 0.5294 - val_acc: 0.8230\n","Epoch 100/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5345 - acc: 0.8121 - val_loss: 0.5144 - val_acc: 0.8196\n","Epoch 101/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5332 - acc: 0.8124 - val_loss: 0.5671 - val_acc: 0.8084\n","Epoch 102/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.5317 - acc: 0.8110 - val_loss: 0.5244 - val_acc: 0.8172\n","Epoch 103/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.5257 - acc: 0.8147 - val_loss: 0.4776 - val_acc: 0.8321\n","Epoch 104/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.5305 - acc: 0.8139 - val_loss: 0.5184 - val_acc: 0.8242\n","Epoch 105/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5268 - acc: 0.8147 - val_loss: 0.5174 - val_acc: 0.8213\n","Epoch 106/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.5261 - acc: 0.8158 - val_loss: 0.5110 - val_acc: 0.8224\n","Epoch 107/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.5256 - acc: 0.8151 - val_loss: 0.5530 - val_acc: 0.8136\n","Epoch 108/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.5230 - acc: 0.8153 - val_loss: 0.5476 - val_acc: 0.8092\n","Epoch 109/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5181 - acc: 0.8177 - val_loss: 0.5045 - val_acc: 0.8275\n","Epoch 110/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5164 - acc: 0.8181 - val_loss: 0.5311 - val_acc: 0.8166\n","Epoch 111/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.5183 - acc: 0.8168 - val_loss: 0.5298 - val_acc: 0.8186\n","Epoch 112/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.5218 - acc: 0.8152 - val_loss: 0.4865 - val_acc: 0.8339\n","Epoch 113/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5129 - acc: 0.8195 - val_loss: 0.4705 - val_acc: 0.8379\n","Epoch 114/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5096 - acc: 0.8205 - val_loss: 0.4855 - val_acc: 0.8346\n","Epoch 115/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.5070 - acc: 0.8233 - val_loss: 0.4993 - val_acc: 0.8303\n","Epoch 116/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.5125 - acc: 0.8191 - val_loss: 0.4927 - val_acc: 0.8331\n","Epoch 117/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5105 - acc: 0.8218 - val_loss: 0.4902 - val_acc: 0.8317\n","Epoch 118/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.5046 - acc: 0.8219 - val_loss: 0.4840 - val_acc: 0.8354\n","Epoch 119/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4992 - acc: 0.8243 - val_loss: 0.5029 - val_acc: 0.8291\n","Epoch 120/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4996 - acc: 0.8251 - val_loss: 0.4943 - val_acc: 0.8302\n","Epoch 121/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5001 - acc: 0.8236 - val_loss: 0.5064 - val_acc: 0.8298\n","Epoch 122/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.5028 - acc: 0.8228 - val_loss: 0.5028 - val_acc: 0.8256\n","Epoch 123/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.5018 - acc: 0.8232 - val_loss: 0.5044 - val_acc: 0.8289\n","Epoch 124/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4943 - acc: 0.8243 - val_loss: 0.5075 - val_acc: 0.8262\n","Epoch 125/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4974 - acc: 0.8255 - val_loss: 0.5252 - val_acc: 0.8239\n","Epoch 126/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4920 - acc: 0.8276 - val_loss: 0.5387 - val_acc: 0.8163\n","Epoch 127/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4891 - acc: 0.8268 - val_loss: 0.4843 - val_acc: 0.8346\n","Epoch 128/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4879 - acc: 0.8286 - val_loss: 0.5055 - val_acc: 0.8266\n","Epoch 129/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4830 - acc: 0.8300 - val_loss: 0.4676 - val_acc: 0.8410\n","Epoch 130/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4882 - acc: 0.8283 - val_loss: 0.7088 - val_acc: 0.7705\n","Epoch 131/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4791 - acc: 0.8327 - val_loss: 0.5249 - val_acc: 0.8206\n","Epoch 132/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4855 - acc: 0.8299 - val_loss: 0.4815 - val_acc: 0.8346\n","Epoch 133/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4799 - acc: 0.8303 - val_loss: 0.5003 - val_acc: 0.8285\n","Epoch 134/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4775 - acc: 0.8315 - val_loss: 0.4966 - val_acc: 0.8334\n","Epoch 135/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4743 - acc: 0.8340 - val_loss: 0.4714 - val_acc: 0.8392\n","Epoch 136/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4769 - acc: 0.8327 - val_loss: 0.4692 - val_acc: 0.8361\n","Epoch 137/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4779 - acc: 0.8321 - val_loss: 0.4916 - val_acc: 0.8340\n","Epoch 138/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4766 - acc: 0.8317 - val_loss: 0.4924 - val_acc: 0.8322\n","Epoch 139/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4776 - acc: 0.8311 - val_loss: 0.4736 - val_acc: 0.8401\n","Epoch 140/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4691 - acc: 0.8346 - val_loss: 0.4857 - val_acc: 0.8339\n","Epoch 141/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4665 - acc: 0.8357 - val_loss: 0.4855 - val_acc: 0.8396\n","Epoch 142/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4637 - acc: 0.8373 - val_loss: 0.4537 - val_acc: 0.8445\n","Epoch 143/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4686 - acc: 0.8347 - val_loss: 0.5075 - val_acc: 0.8331\n","Epoch 144/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4670 - acc: 0.8350 - val_loss: 0.4619 - val_acc: 0.8429\n","Epoch 145/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4656 - acc: 0.8354 - val_loss: 0.4685 - val_acc: 0.8393\n","Epoch 146/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4635 - acc: 0.8379 - val_loss: 0.4749 - val_acc: 0.8366\n","Epoch 147/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4627 - acc: 0.8374 - val_loss: 0.4451 - val_acc: 0.8464\n","Epoch 148/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4629 - acc: 0.8371 - val_loss: 0.4761 - val_acc: 0.8396\n","Epoch 149/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4618 - acc: 0.8361 - val_loss: 0.5171 - val_acc: 0.8264\n","Epoch 150/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4672 - acc: 0.8365 - val_loss: 0.4873 - val_acc: 0.8351\n","Epoch 151/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4634 - acc: 0.8365 - val_loss: 0.4856 - val_acc: 0.8366\n","Epoch 152/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4535 - acc: 0.8421 - val_loss: 0.4676 - val_acc: 0.8403\n","Epoch 153/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4597 - acc: 0.8371 - val_loss: 0.4962 - val_acc: 0.8269\n","Epoch 154/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4589 - acc: 0.8389 - val_loss: 0.4741 - val_acc: 0.8414\n","Epoch 155/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4574 - acc: 0.8390 - val_loss: 0.4550 - val_acc: 0.8449\n","Epoch 156/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4526 - acc: 0.8409 - val_loss: 0.4733 - val_acc: 0.8390\n","Epoch 157/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4488 - acc: 0.8434 - val_loss: 0.4459 - val_acc: 0.8486\n","Epoch 158/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4554 - acc: 0.8386 - val_loss: 0.4838 - val_acc: 0.8371\n","Epoch 159/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4508 - acc: 0.8401 - val_loss: 0.4651 - val_acc: 0.8456\n","Epoch 160/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4506 - acc: 0.8429 - val_loss: 0.4547 - val_acc: 0.8466\n","Epoch 161/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4476 - acc: 0.8412 - val_loss: 0.4463 - val_acc: 0.8507\n","Epoch 162/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4505 - acc: 0.8421 - val_loss: 0.4489 - val_acc: 0.8480\n","Epoch 163/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4469 - acc: 0.8428 - val_loss: 0.4713 - val_acc: 0.8415\n","Epoch 164/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4457 - acc: 0.8435 - val_loss: 0.5144 - val_acc: 0.8301\n","Epoch 165/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4443 - acc: 0.8445 - val_loss: 0.4610 - val_acc: 0.8445\n","Epoch 166/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4440 - acc: 0.8440 - val_loss: 0.4942 - val_acc: 0.8327\n","Epoch 167/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4436 - acc: 0.8428 - val_loss: 0.4773 - val_acc: 0.8395\n","Epoch 168/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4414 - acc: 0.8447 - val_loss: 0.4733 - val_acc: 0.8427\n","Epoch 169/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4373 - acc: 0.8470 - val_loss: 0.4830 - val_acc: 0.8355\n","Epoch 170/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4425 - acc: 0.8434 - val_loss: 0.4865 - val_acc: 0.8364\n","Epoch 171/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4432 - acc: 0.8429 - val_loss: 0.4578 - val_acc: 0.8477\n","Epoch 172/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4408 - acc: 0.8443 - val_loss: 0.4551 - val_acc: 0.8445\n","Epoch 173/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4436 - acc: 0.8442 - val_loss: 0.4636 - val_acc: 0.8451\n","Epoch 174/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4369 - acc: 0.8467 - val_loss: 0.4493 - val_acc: 0.8475\n","Epoch 175/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4384 - acc: 0.8453 - val_loss: 0.5146 - val_acc: 0.8256\n","Epoch 176/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4362 - acc: 0.8478 - val_loss: 0.4897 - val_acc: 0.8394\n","Epoch 177/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4374 - acc: 0.8453 - val_loss: 0.4660 - val_acc: 0.8442\n","Epoch 178/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4327 - acc: 0.8472 - val_loss: 0.4866 - val_acc: 0.8375\n","Epoch 179/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4267 - acc: 0.8489 - val_loss: 0.4657 - val_acc: 0.8435\n","Epoch 180/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4279 - acc: 0.8493 - val_loss: 0.4413 - val_acc: 0.8518\n","Epoch 181/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4289 - acc: 0.8507 - val_loss: 0.4668 - val_acc: 0.8426\n","Epoch 182/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4274 - acc: 0.8487 - val_loss: 0.4698 - val_acc: 0.8450\n","Epoch 183/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4281 - acc: 0.8493 - val_loss: 0.4499 - val_acc: 0.8469\n","Epoch 184/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4309 - acc: 0.8473 - val_loss: 0.4715 - val_acc: 0.8443\n","Epoch 185/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4301 - acc: 0.8490 - val_loss: 0.4593 - val_acc: 0.8449\n","Epoch 186/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4209 - acc: 0.8515 - val_loss: 0.4554 - val_acc: 0.8444\n","Epoch 187/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4248 - acc: 0.8505 - val_loss: 0.4492 - val_acc: 0.8509\n","Epoch 188/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4263 - acc: 0.8494 - val_loss: 0.4640 - val_acc: 0.8420\n","Epoch 189/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4214 - acc: 0.8527 - val_loss: 0.4798 - val_acc: 0.8425\n","Epoch 190/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4236 - acc: 0.8507 - val_loss: 0.4733 - val_acc: 0.8399\n","Epoch 191/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4227 - acc: 0.8505 - val_loss: 0.4640 - val_acc: 0.8464\n","Epoch 192/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4181 - acc: 0.8516 - val_loss: 0.4470 - val_acc: 0.8491\n","Epoch 193/200\n","50000/50000 [==============================] - 8s 152us/step - loss: 0.4189 - acc: 0.8528 - val_loss: 0.4758 - val_acc: 0.8433\n","Epoch 194/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4220 - acc: 0.8511 - val_loss: 0.4799 - val_acc: 0.8431\n","Epoch 195/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4214 - acc: 0.8503 - val_loss: 0.4634 - val_acc: 0.8459\n","Epoch 196/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4228 - acc: 0.8520 - val_loss: 0.4337 - val_acc: 0.8558\n","Epoch 197/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4133 - acc: 0.8538 - val_loss: 0.4499 - val_acc: 0.8483\n","Epoch 198/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4141 - acc: 0.8545 - val_loss: 0.4507 - val_acc: 0.8456\n","Epoch 199/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4163 - acc: 0.8535 - val_loss: 0.4498 - val_acc: 0.8469\n","Epoch 200/200\n","50000/50000 [==============================] - 8s 151us/step - loss: 0.4154 - acc: 0.8540 - val_loss: 0.4562 - val_acc: 0.8480\n","10000/10000 [==============================] - 2s 188us/step\n","Test score: 0.4561866389155388\n","Text Accuracy: 84.8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6JwtxoeopQvc","colab_type":"code","outputId":"e69a1188-b274-40cd-9f8d-494b718361bf","colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k71UEDU4vL6d","colab_type":"code","colab":{}},"source":["storage_client = st.Client.from_service_account_json('/content/drive/My Drive/JSON/objectdtection-feabc8d45d12.json')\n","bucket=storage_client.get_bucket('objectdtection.appspot.com')\n","image=bucket.blob('ddd.jpg')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dO_RD-THwRPh","colab_type":"code","colab":{}},"source":["url=image.public_url\n","import urllib\n","req=urllib.request.urlopen(url)\n","imageF=np.asarray(bytearray(req.read()),dtype=np.uint8)\n","img=cv2.imdecode(imageF,-1)\n","requiredSize = (32,32)\n","imageUpload = cv2.resize(img, requiredSize)\n","imageUpload = np.reshape(imageUpload,(1,32,32,3))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kXVwo_-WxOnd","colab_type":"code","outputId":"542fb019-7bf9-4f8d-9f6d-1ed6039ddb55","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["bestProbability = model.predict_proba(imageUpload)\n","availableClasses = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n","bestProbability = bestProbability.astype('int')\n","maxValue = np.argmax(bestProbability)\n","answer = availableClasses[maxValue]\n","\n","count = 0\n","for i in bestProbability[0]:\n","  if bestProbability[0][0] == i:\n","    count = count + 1\n","if count == 10:\n","  print(\"Not Recognized\")\n","else:\n","  answerOutput = \"The Recognized Object is a : \" + answer\n","  print(answerOutput)\n","  fire=fb.FirebaseApplication('https://objectdtection.firebaseio.com/')\n","  fire.put('https://objectdtection.firebaseio.com/','Answer',answerOutput)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The Recognized Object is a : truck\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i2TA7AtdxcYQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}